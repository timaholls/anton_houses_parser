#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö DomRF, Avito –∏ DomClick.
–õ–æ–≥–∏–∫–∞:
1. –ë–µ—Ä–µ–º –∑–∞–ø–∏—Å—å –∏–∑ DomRF
2. –ò—â–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤ Avito
3. –ò—â–µ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤ DomClick –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
4. –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
"""
import json
import os
import re
from pathlib import Path
from pymongo import MongoClient
from dotenv import load_dotenv
from typing import Dict, List, Any, Optional
from rapidfuzz import fuzz

# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
PROJECT_ROOT = Path(__file__).resolve().parent

# –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
UNIFIED_COLLECTION_NAME = "unified_houses"


def load_env_from_parser(parser_name):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
    env_path = PROJECT_ROOT / parser_name / ".env"
    if env_path.exists():
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        original_env = dict(os.environ)

        # –û—á–∏—â–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for key in ['DB_NAME', 'COLLECTION_NAME', 'MONGO_URI']:
            if key in os.environ:
                del os.environ[key]

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ .env —Ñ–∞–π–ª–∞
        load_dotenv(dotenv_path=env_path, override=True)

        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        config = {
            "DB_NAME": os.getenv("DB_NAME"),
            "COLLECTION_NAME": os.getenv("COLLECTION_NAME"),
            "MONGO_URI": os.getenv("MONGO_URI")
        }

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        os.environ.clear()
        os.environ.update(original_env)

        return config
    return None


def transliterate_russian_to_latin(text: str) -> str:
    """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É"""
    translit_dict = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'Yo',
        '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Sch',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
    }

    result = ""
    for char in text:
        result += translit_dict.get(char, char)
    return result


def normalize_name_simple(name: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è rapidfuzz"""
    if not name:
        return ""

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    name = name.lower().strip()

    # –£–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏, –ø–æ—è—Å–Ω–µ–Ω–∏—è)
    name = re.sub(r'\([^)]*\)', '', name)

    # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã (–≤–∫–ª—é—á–∞—è —Ç–æ—á–∫–∏, —Ç–∏—Ä–µ, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
    name = re.sub(r'[¬´¬ª""\[\].‚Äî‚Äì\-_&]', ' ', name)

    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
    prefixes = ['–∂–∫', '—Ç–æ–∫', '–∫–æ–º–ø–ª–µ–∫—Å –∂–∏–ª—ã—Ö –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', '–∫–æ–º–ø–ª–µ–∫—Å –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤',
                '–∫–æ–º–ø–ª–µ–∫—Å –≤—ã—Å–æ—Ç–Ω—ã—Ö –¥–æ–º–æ–≤', '–∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å', '–∫–ª—É–±–Ω—ã–π –¥–æ–º',
                '–∫–ª—É–±–Ω–∞—è —Ä–µ–∑–∏–¥–µ–Ω—Ü–∏—è', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '—Å–µ–º–µ–π–Ω—ã–π –∫–≤–∞—Ä—Ç–∞–ª',
                '–∑–Ω–∞–∫–æ–≤—ã–π –∫–≤–∞—Ä—Ç–∞–ª', '–∫—Ä–∞—Å–æ—á–Ω—ã–π –∫–≤–∞—Ä—Ç–∞–ª', '–∫–≤–∞—Ä—Ç–∞–ª']

    for prefix in prefixes:
        pattern = r'\b' + re.escape(prefix) + r'\b\s*'
        name = re.sub(pattern, '', name, flags=re.IGNORECASE)

    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    name = re.sub(r'\s+', ' ', name).strip()

    return name


def normalize_name(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ñ–ö –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
    if not name:
        return ""

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    normalized = name.lower()

    # –£–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—á–∞—Å—Ç–æ —Ç–∞–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
    normalized = re.sub(r'\([^)]*\)', '', normalized)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–±–µ–ª—ã
    normalized = re.sub(r'[^\w\s]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–Ω–æ –ù–ï —É–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ —Ç–∏–ø–∞ "village", "park")
    common_words = ['–∂–∫', '–∂–∏–ª–æ–π', '–∫–æ–º–ø–ª–µ–∫—Å', '–¥–æ–º–∞', '–∫–≤–∞—Ä—Ç–∏—Ä—ã', '–ø–æ—Å–µ–ª–æ–∫',
                    '–ª–∏—Ç–µ—Ä', '–ª–∏—Ç–µ—Ä–∞', '—Å–µ–∫—Ü–∏–∏', '—ç—Ç–∞–ø', '–æ—á–µ—Ä–µ–¥—å',
                    '–∫–ª—É–±–Ω—ã–π', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '–∫—Ä–∞—Å–æ—á–Ω—ã–π',
                    '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã', '–≤—ã—Å–æ—Ç–Ω—ã—Ö', '—ç–∫–æ–≥–æ—Ä–æ–¥',
                    '–∫–ª—É–±–Ω–∞—è', '—Ä–µ–∑–∏–¥–µ–Ω—Ü–∏—è', '–≥—Ä—É–ø–ø–∞', '–∫–æ–º–ø–∞–Ω–∏–π', '–∫–æ–º–ø–ª–µ–∫—Å–∞']

    # –ó–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –¥–æ–ª–∂–Ω—ã —É–¥–∞–ª—è—Ç—å—Å—è
    significant_words = {'village', '–≤–∏–ª–ª–∏–¥–∂', 'park', '–ø–∞—Ä–∫', 'city', '—Å–∏—Ç–∏',
                         'town', '—Ç–∞—É–Ω', 'garden', '–≥–∞—Ä–¥–µ–Ω', 'house', '—Ö–∞—É—Å',
                         'collection', '–∫–æ–ª–ª–µ–∫—à–Ω', '–∫–≤–∞—Ä—Ç–∞–ª', 'premiere', '–ø—Ä–µ–º—å–µ—Ä',
                         '—É–º–Ω—ã–π', 'smart', '–¥–æ–º', 'the', 'prime'}

    for word in common_words:
        # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ–µ (–Ω–µ —á–∞—Å—Ç—å –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞) –∏ –Ω–µ –∑–Ω–∞—á–∏–º–æ–µ
        if word not in significant_words:
            normalized = re.sub(r'\b' + word + r'\b', '', normalized)

    # –£–±–∏—Ä–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ —Å—Ç–æ—è—â–∏–µ —Ü–∏—Ñ—Ä—ã –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –±—É–∫–≤—ã (–Ω–æ–º–µ—Ä–∞ –ª–∏—Ç–µ—Ä–æ–≤, —ç—Ç–∞–ø–æ–≤, —Å–µ–∫—Ü–∏–π)
    # –ù–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ñ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏—è (8 –º–∞—Ä—Ç–∞, 535)
    words = normalized.split()
    filtered_words = []
    for i, word in enumerate(words):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –Ω–æ–º–µ—Ä–∞–º–∏ –ª–∏—Ç–µ—Ä–æ–≤/—Å–µ–∫—Ü–∏–π/—ç—Ç–∞–ø–æ–≤
        if (word.isdigit() or  # –û–¥–∏–Ω–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã
                (len(word) <= 3 and word.isalpha() and word not in significant_words) or  # –ö–æ—Ä–æ—Ç–∫–∏–µ –±—É–∫–≤—ã
                word in ['–ª–∏—Ç–µ—Ä', '–ª–∏—Ç–µ—Ä–∞', '—Å–µ–∫—Ü–∏–∏', '—Å–µ–∫—Ü–∏—è', '—ç—Ç–∞–ø', '–æ—á–µ—Ä–µ–¥—å', '–ø–∞—Ä–∫–∏–Ω–≥']):  # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
            continue
        filtered_words.append(word)

    normalized = ' '.join(filtered_words)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    transliterated = transliterate_russian_to_latin(normalized)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    if normalized != transliterated:
        return f"{normalized} {transliterated}"
    else:
        return normalized


def find_matching_avito_record(domrf_record: Dict, avito_collection, used_avito_ids: set) -> Optional[Dict]:
    """–ò—â–µ—Ç –∑–∞–ø–∏—Å—å –≤ Avito –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ñ–ö, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏"""
    domrf_name = domrf_record.get('objCommercNm')
    if not domrf_name:
        return None

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ DomRF –∑–∞–ø–∏—Å–∏
    normalized_domrf = domrf_record.get('normalized_name')
    if not normalized_domrf:
        # –ï—Å–ª–∏ –ø–æ–ª–µ normalized_name –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ–º –µ–≥–æ
        normalized_domrf = normalize_name(domrf_name)

    print(f"üîç DomRF: '{domrf_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_domrf}'")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ Avito, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
    avito_records = list(avito_collection.find({'_id': {'$nin': list(used_avito_ids)}}))

    best_match = None
    best_score = 0
    comparison_count = 0

    for record in avito_records:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ development.name
        development = record.get('development', {})
        avito_name = development.get('name', '')

        if not avito_name:
            continue

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ Avito
        normalized_avito = normalize_name(avito_name)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É—è rapidfuzz
        similarity_score = calculate_similarity_rapidfuzz(domrf_name, avito_name)
        comparison_count += 1

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å > 0.3 (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
        if similarity_score > 0.3:
            print(f"  üìã Avito: '{avito_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_avito}' | –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")

        if similarity_score > best_score and similarity_score > 0.60:  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            print(f"    ‚úÖ –ù–û–í–û–ï –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï! –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")
            best_score = similarity_score
            best_match = record
        elif similarity_score > 0.5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±–ª–∏–∑–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            print(f"    ‚ö†Ô∏è  –ë–ª–∏–∑–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–Ω—É–∂–Ω–æ >0.60)")

    print(f"üìä –°—Ä–∞–≤–Ω–µ–Ω–æ —Å {comparison_count} –∑–∞–ø–∏—Å—è–º–∏ –∏–∑ Avito (–¥–æ—Å—Ç—É–ø–Ω–æ: {len(avito_records)})")
    if best_match:
        development = best_match.get('development', {})
        avito_name = development.get('name', '')
        print(f"üèÜ –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï: '{avito_name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {best_score:.2f})")
    else:
        print(f"‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: 0.60)")

    print()
    return best_match


def find_matching_domclick_record(domrf_record: Dict, domclick_collection, used_domclick_ids: set) -> Optional[Dict]:
    """–ò—â–µ—Ç –∑–∞–ø–∏—Å—å –≤ DomClick –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ñ–ö, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏"""
    domrf_name = domrf_record.get('objCommercNm')
    if not domrf_name:
        return None

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ DomRF –∑–∞–ø–∏—Å–∏
    normalized_domrf = domrf_record.get('normalized_name')
    if not normalized_domrf:
        # –ï—Å–ª–∏ –ø–æ–ª–µ normalized_name –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ–º –µ–≥–æ
        normalized_domrf = normalize_name(domrf_name)

    print(f"üîç DomRF: '{domrf_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_domrf}'")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomClick, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
    domclick_records = list(domclick_collection.find({'_id': {'$nin': list(used_domclick_ids)}}))

    best_match = None
    best_score = 0
    comparison_count = 0

    for record in domclick_records:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ development.complex_name
        development = record.get('development', {})
        domclick_name = development.get('complex_name', '')

        if not domclick_name:
            continue

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ DomClick
        normalized_domclick = normalize_name(domclick_name)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É—è rapidfuzz
        similarity_score = calculate_similarity_rapidfuzz(domrf_name, domclick_name)
        comparison_count += 1

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å > 0.3 (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
        if similarity_score > 0.3:
            print(
                f"  üìã DomClick: '{domclick_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_domclick}' | –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")

        if similarity_score > best_score and similarity_score > 0.60:  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            print(f"    ‚úÖ –ù–û–í–û–ï –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï! –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")
            best_score = similarity_score
            best_match = record
        elif similarity_score > 0.5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±–ª–∏–∑–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            print(f"    ‚ö†Ô∏è  –ë–ª–∏–∑–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–Ω—É–∂–Ω–æ >0.60)")

    print(f"üìä –°—Ä–∞–≤–Ω–µ–Ω–æ —Å {comparison_count} –∑–∞–ø–∏—Å—è–º–∏ –∏–∑ DomClick (–¥–æ—Å—Ç—É–ø–Ω–æ: {len(domclick_records)})")
    if best_match:
        development = best_match.get('development', {})
        domclick_name = development.get('complex_name', '')
        print(f"üèÜ –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï: '{domclick_name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {best_score:.2f})")
    else:
        print(f"‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: 0.60)")

    print()
    return best_match


def split_compound_word(word: str, other_words: set) -> set:
    """–ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞–∑–±–∏—Ç—å —Å–ª–∏—Ç–æ–µ —Å–ª–æ–≤–æ –Ω–∞ —á–∞—Å—Ç–∏, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤–∞—Ö"""
    if len(word) < 6:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏
        return {word}

    # –ò—â–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    parts = set()
    parts.add(word)  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ

    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–∞—Å—Ç–∏ —Å–ª–æ–≤–∞ –≤ –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤–∞—Ö
    for other_word in other_words:
        if other_word in word:
            # –ù–∞–π–¥–µ–Ω–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ - –¥–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç–∏
            remaining = word.replace(other_word, '')
            if remaining:
                parts.add(other_word)
                parts.add(remaining)
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                remaining_parts = split_compound_word(remaining, other_words - {other_word})
                parts.update(remaining_parts)

    # –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –ø–æ –¥–ª–∏–Ω–µ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
    if len(word) > 8:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ–ø–æ–ª–∞–º
        mid = len(word) // 2
        part1 = word[:mid]
        part2 = word[mid:]
        if len(part1) >= 3 and len(part2) >= 3:
            parts.add(part1)
            parts.add(part2)

    return parts


def calculate_similarity_rapidfuzz(name1: str, name2: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –ñ–ö –∏—Å–ø–æ–ª—å–∑—É—è rapidfuzz —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
    if not name1 or not name2:
        return 0.0

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
    norm1 = normalize_name_simple(name1)
    norm2 = normalize_name_simple(name2)

    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä—è–º–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–æ–±–∞ –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ –∏–ª–∏ –æ–±–∞ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_direct = fuzz.token_sort_ratio(norm1, norm2, processor=str.lower)

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –æ–±–∞ –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    trans1 = transliterate_russian_to_latin(norm1)
    trans2 = transliterate_russian_to_latin(norm2)
    ratio_transliterated = fuzz.token_sort_ratio(trans1, trans2, processor=str.lower)

    # –í–∞—Ä–∏–∞–Ω—Ç 3: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º norm1 —Å trans2 (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ –æ–¥–∏–Ω —É–∂–µ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_cross1 = fuzz.token_sort_ratio(norm1, trans2, processor=str.lower)

    # –í–∞—Ä–∏–∞–Ω—Ç 4: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º trans1 —Å norm2 (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ –≤—Ç–æ—Ä–æ–π —É–∂–µ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_cross2 = fuzz.token_sort_ratio(trans1, norm2, processor=str.lower)

    # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    max_ratio = max(ratio_direct, ratio_transliterated, ratio_cross1, ratio_cross2)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 0-1 –¥–∏–∞–ø–∞–∑–æ–Ω
    return max_ratio / 100.0


def calculate_similarity(name1: str, name2: str) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –ñ–ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏.
    –ö–ª—é—á–µ–≤–∞—è –ª–æ–≥–∏–∫–∞:
    - –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ - –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
    - –ï—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è (village, park –∏ —Ç.–¥.) - –Ω–∏–∑–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
    """
    if not name1 or not name2:
        return 0.0

    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if name1 == name2:
        return 1.0

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words1 = set(name1.split())
    words2 = set(name2.split())

    if not words1 or not words2:
        return 0.0

    # –°–ø–∏—Å–æ–∫ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–∞—Ä–∞–º (—Ä—É—Å—Å–∫–æ–µ, –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ)
    significant_pairs = [
        ('village', '–≤–∏–ª–ª–∏–¥–∂'), ('park', '–ø–∞—Ä–∫'), ('city', '—Å–∏—Ç–∏'),
        ('town', '—Ç–∞—É–Ω'), ('garden', '–≥–∞—Ä–¥–µ–Ω'), ('house', '—Ö–∞—É—Å'),
        ('collection', '–∫–æ–ª–ª–µ–∫—à–Ω'), ('premiere', '–ø—Ä–µ–º—å–µ—Ä'),
        ('smart', '—É–º–Ω—ã–π'), ('prime', '–ø—Ä–∞–π–º')
    ]

    # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    significant_words = set()
    for eng, rus in significant_pairs:
        significant_words.add(eng)
        significant_words.add(rus)

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –±–µ–∑ –ø–∞—Ä
    significant_words.update({'–∫–≤–∞—Ä—Ç–∞–ª', '–¥–æ–º', 'the'})

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ —Å —É—á–µ—Ç–æ–º –ø–∞—Ä
    def get_significant_concepts(words):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ (—É—á–∏—Ç—ã–≤–∞—è –ø–∞—Ä—ã)"""
        concepts = set()
        for word in words:
            if word in significant_words:
                # –ò—â–µ–º –ø–∞—Ä—É –¥–ª—è —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞
                found_pair = False
                for eng, rus in significant_pairs:
                    if word in (eng, rus):
                        concepts.add((eng, rus))
                        found_pair = True
                        break
                if not found_pair:
                    concepts.add((word,))  # –°–ª–æ–≤–æ –±–µ–∑ –ø–∞—Ä—ã
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –∑–Ω–∞—á–∏–º–æ–µ —Å–ª–æ–≤–æ –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞
                for eng, rus in significant_pairs:
                    if eng in word or rus in word:
                        concepts.add((eng, rus))
        return concepts

    concepts_1 = get_significant_concepts(words1)
    concepts_2 = get_significant_concepts(words2)

    # –ï—Å–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç - —ç—Ç–æ —Ä–∞–∑–Ω—ã–µ –ñ–ö
    if concepts_1 != concepts_2 and (concepts_1 or concepts_2):
        # –î–∞–∂–µ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø–æ—Ö–æ–∂–∞, —ç—Ç–æ —Ä–∞–∑–Ω—ã–µ –∫–æ–º–ø–ª–µ–∫—Å—ã
        return 0.6  # –ù–µ –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç –ø–æ—Ä–æ–≥–∞ 0.8

    # –ï—Å–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –¥–∞–µ–º –±–æ–Ω—É—Å
    concept_bonus = 0.0
    if concepts_1 == concepts_2 and concepts_1:
        concept_bonus = 0.3  # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

    # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ –∏ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã)
    stop_words = {'–Ω–æ–≤—ã–π', '—Å—Ç–∞—Ä—ã–π', '–±–æ–ª—å—à–æ–π', '–º–∞–ª–µ–Ω—å–∫–∏–π'}

    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
    filtered_words1 = {word for word in words1 if word not in stop_words}
    filtered_words2 = {word for word in words2 if word not in stop_words}

    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–æ–≤
    if not filtered_words1 or not filtered_words2:
        return 0.0

    # –û–¥–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä—É–≥–æ–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é
    if filtered_words1 == filtered_words2:
        return 1.0

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–∞–∑–±–∏–≤–∫–∏ —Å–ª–∏—Ç—ã—Ö —Å–ª–æ–≤
    # –ò—â–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
    all_words1 = filtered_words1.copy()
    all_words2 = filtered_words2.copy()

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
    for word in list(filtered_words1):
        if any(ord(c) > 127 for c in word):  # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
            transliterated = transliterate_russian_to_latin(word)
            if transliterated != word:
                all_words1.add(transliterated)

    for word in list(filtered_words2):
        if any(ord(c) > 127 for c in word):  # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
            transliterated = transliterate_russian_to_latin(word)
            if transliterated != word:
                all_words2.add(transliterated)

    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Å–ª–∏—Ç—ã–µ —Å–ª–æ–≤–∞
    for word in list(all_words1):
        if len(word) > 8:  # –î–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—Ç—ã–º–∏
            parts = split_compound_word(word, all_words2)
            all_words1.update(parts)

    for word in list(all_words2):
        if len(word) > 8:  # –î–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—Ç—ã–º–∏
            parts = split_compound_word(word, all_words1)
            all_words2.update(parts)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    common_words = all_words1.intersection(all_words2)

    if common_words:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–≤–∫–ª—é—á–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏), –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        similarity1 = len(common_words) / len(filtered_words1)
        similarity2 = len(common_words) / len(filtered_words2)

        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ –º—è–≥–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        avg_similarity = (similarity1 + similarity2) / 2

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –±–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        avg_similarity += concept_bonus

        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
        if avg_similarity >= 0.7:
            return min(0.95, avg_similarity + 0.1)  # –ë–æ–Ω—É—Å –∑–∞ —Ö–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        elif avg_similarity >= 0.5:
            return avg_similarity * 0.95
        else:
            return avg_similarity * 0.8

    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º—ã—Ö –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    if filtered_words1.issubset(all_words2):
        extra_words = all_words2 - filtered_words1
        if len(extra_words) <= 4:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
            return min(0.95, 0.9 + concept_bonus)
        return min(0.95, 0.8 + concept_bonus)

    if filtered_words2.issubset(all_words1):
        extra_words = all_words1 - filtered_words2
        if len(extra_words) <= 4:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
            return min(0.95, 0.9 + concept_bonus)
        return min(0.95, 0.8 + concept_bonus)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    for word1 in filtered_words1:
        for word2 in filtered_words2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if word1 == word2:
                return min(0.95, 0.85 + concept_bonus)  # –•–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –≤ –¥—Ä—É–≥–æ–º (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–∞–∫ "zorgepremer" vs "zorge")
            if len(word1) > 6 and len(word2) > 3:  # word1 –¥–ª–∏–Ω–Ω–æ–µ, word2 –∫–æ—Ä–æ—Ç–∫–æ–µ
                if word2 in word1:
                    remaining = word1.replace(word2, '')
                    if len(remaining) <= 4:  # –û—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ —Å–∏–º–≤–æ–ª–æ–≤
                        return min(0.95, 0.9 + concept_bonus)
            elif len(word2) > 6 and len(word1) > 3:  # word2 –¥–ª–∏–Ω–Ω–æ–µ, word1 –∫–æ—Ä–æ—Ç–∫–æ–µ
                if word1 in word2:
                    remaining = word2.replace(word1, '')
                    if len(remaining) <= 4:  # –û—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ —Å–∏–º–≤–æ–ª–æ–≤
                        return min(0.95, 0.9 + concept_bonus)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
            if len(word1) > 3 and len(word2) > 3:  # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤
                translit1 = transliterate_russian_to_latin(word1)
                translit2 = transliterate_russian_to_latin(word2)

                if translit1 == word2 or word1 == translit2 or translit1 == translit2:
                    return min(0.95, 0.9 + concept_bonus)  # –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
                if len(translit1) > 6 and len(word2) > 3:
                    if word2 in translit1:
                        remaining = translit1.replace(word2, '')
                        if len(remaining) <= 4:
                            return min(0.95, 0.9 + concept_bonus)
                elif len(translit2) > 6 and len(word1) > 3:
                    if word1 in translit2:
                        remaining = translit2.replace(word1, '')
                        if len(remaining) <= 4:
                            return min(0.95, 0.9 + concept_bonus)

    return 0.0


def extract_photos_from_domclick(domclick_record: Dict) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∏–∑ –∑–∞–ø–∏—Å–∏ DomClick"""
    photos = []

    if not domclick_record:
        return photos

    # –ò—â–µ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    development = domclick_record.get('development', {})

    # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∏–∑ development
    if 'photos' in development:
        photos.extend(development['photos'])

    # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∏–∑ apartment_types
    apartment_types = domclick_record.get('apartment_types', {})
    for apt_type, apt_data in apartment_types.items():
        if isinstance(apt_data, dict) and 'photos' in apt_data:
            photos.extend(apt_data['photos'])

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    photos = list(set(photos))

    return photos


def create_unified_record(domrf_record: Dict, avito_record: Optional[Dict],
                          domclick_record: Optional[Dict]) -> Dict:
    """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""

    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ DomRF (—Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è)
    unified_record = {
        '_id': domrf_record.get('_id'),
        'source': 'unified',
        'created_at': domrf_record.get('details_extracted_at'),
        'domrf_data': {
            'latitude': domrf_record.get('latitude'),
            'longitude': domrf_record.get('longitude'),
            'object_details': domrf_record.get('object_details', {}),
            'developer': domrf_record.get('developer', {}),
            'objCommercNm': domrf_record.get('objCommercNm')
        }
    }

    # –î–∞–Ω–Ω—ã–µ –∏–∑ Avito (–≤—Å–µ –ø–æ–ª—è)
    if avito_record:
        unified_record['avito_data'] = avito_record

    # –î–∞–Ω–Ω—ã–µ –∏–∑ DomClick (apartment_types –∏ development)
    if domclick_record:
        unified_record['domclick_data'] = {
            'apartment_types': domclick_record.get('apartment_types', {}),
            'development': domclick_record.get('development', {})
        }

    return unified_record


def create_unified_collection():
    """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
    print("üöÄ –°–û–ó–î–ê–ù–ò–ï –û–ë–™–ï–î–ò–ù–ï–ù–ù–û–ô –ö–û–õ–õ–ï–ö–¶–ò–ò")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    domrf_config = load_env_from_parser('domrf')
    avito_config = load_env_from_parser('avito')
    domclick_config = load_env_from_parser('domclick')

    if not all([domrf_config, avito_config, domclick_config]):
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MongoDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é DomRF –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é)
        client = MongoClient(domrf_config['MONGO_URI'])
        db = client[domrf_config['DB_NAME']]

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        domrf_collection = db[domrf_config['COLLECTION_NAME']]
        avito_collection = db[avito_config['COLLECTION_NAME']]
        domclick_collection = db[domclick_config['COLLECTION_NAME']]

        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ—á–∏—â–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
        unified_collection = db[UNIFIED_COLLECTION_NAME]
        unified_collection.drop()  # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é

        print(f"üìä –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –±–∞–∑–µ: {domrf_config['DB_NAME']}")
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è DomRF: {domrf_config['COLLECTION_NAME']}")
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è Avito: {avito_config['COLLECTION_NAME']}")
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è DomClick: {domclick_config['COLLECTION_NAME']}")
        print(f"üìä –ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {UNIFIED_COLLECTION_NAME}")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomRF
        print(f"\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–ø–∏—Å–∏ –∏–∑ DomRF...")
        domrf_records = list(domrf_collection.find())
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(domrf_records)} –∑–∞–ø–∏—Å–µ–π –∏–∑ DomRF")

        # –ù–∞–±–æ—Ä—ã –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        used_avito_ids = set()
        used_domclick_ids = set()
        unmatched_domrf = []

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å
        processed_count = 0
        matched_avito = 0
        matched_domclick = 0
        skipped_no_avito = 0
        skipped_no_domclick = 0

        for i, domrf_record in enumerate(domrf_records):
            if i % 10 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(domrf_records)}")

            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ñ–ö –∏–∑ DomRF
            domrf_name = domrf_record.get('objCommercNm')
            if not domrf_name:
                continue

            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ Avito (–∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ)
            avito_match = find_matching_avito_record(domrf_record, avito_collection, used_avito_ids)
            if avito_match:
                matched_avito += 1
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö
                used_avito_ids.add(avito_match['_id'])
            else:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ Avito - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É –∑–∞–ø–∏—Å—å
                skipped_no_avito += 1
                unmatched_domrf.append({
                    'name': domrf_name,
                    'objId': domrf_record.get('objId'),
                    'reason': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ Avito'
                })
                continue

            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ DomClick (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –≤ Avito, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ)
            domclick_match = find_matching_domclick_record(domrf_record, domclick_collection, used_domclick_ids)
            if domclick_match:
                matched_domclick += 1
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö
                used_domclick_ids.add(domclick_match['_id'])
            else:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ DomClick - —Ç–æ–∂–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                skipped_no_domclick += 1
                unmatched_domrf.append({
                    'name': domrf_name,
                    'objId': domrf_record.get('objId'),
                    'reason': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ DomClick'
                })
                continue

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –∏ –≤ Avito, –∏ –≤ DomClick)
            unified_record = create_unified_record(domrf_record, avito_match, domclick_match)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
            unified_collection.insert_one(unified_record)
            processed_count += 1

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π DomRF: {len(domrf_records)}")
        print(f"  ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {processed_count}")
        print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –≤ Avito): {skipped_no_avito}")
        print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –≤ DomClick): {skipped_no_domclick}")
        print(f"  ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ Avito: {matched_avito}")
        print(f"  ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ DomClick: {matched_domclick}")
        print(f"  ‚Ä¢ –ó–∞–ø–∏—Å–µ–π –≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {unified_collection.count_documents({})}")

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        print(f"\nüîç –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã...")
        unified_collection.create_index("domrf_data.objCommercNm")
        unified_collection.create_index("domrf_data.latitude")
        unified_collection.create_index("domrf_data.longitude")

        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ Avito –∏ DomClick
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–• –ó–ê–ü–ò–°–ï–ô...")

        # –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ Avito
        unmatched_avito = list(avito_collection.find({'_id': {'$nin': list(used_avito_ids)}}))

        # –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomClick
        unmatched_domclick = list(domclick_collection.find({'_id': {'$nin': list(used_domclick_ids)}}))

        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π DomRF
        if unmatched_domrf:
            print(f"\n{'=' * 120}")
            print(f"üìã –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ó–ê–ü–ò–°–ò –ò–ó DOMRF ({len(unmatched_domrf)} —à—Ç.)")
            print(f"{'=' * 120}")
            print(f"{'‚Ññ':<5} {'–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö':<50} {'objId':<15} {'–ü—Ä–∏—á–∏–Ω–∞':<40}")
            print(f"{'-' * 120}")
            for idx, record in enumerate(unmatched_domrf[:50], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 50
                name = record['name'][:48] if len(record['name']) > 48 else record['name']
                obj_id = str(record['objId'])[:13] if record['objId'] else 'N/A'
                reason = record['reason'][:38] if len(record['reason']) > 38 else record['reason']
                print(f"{idx:<5} {name:<50} {obj_id:<15} {reason:<40}")
            if len(unmatched_domrf) > 50:
                print(f"... –∏ –µ—â–µ {len(unmatched_domrf) - 50} –∑–∞–ø–∏—Å–µ–π")
        else:
            print(f"\n‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomRF —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã!")

        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π Avito
        if unmatched_avito:
            print(f"\n{'=' * 120}")
            print(f"üìã –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ó–ê–ü–ò–°–ò –ò–ó AVITO ({len(unmatched_avito)} —à—Ç.)")
            print(f"{'=' * 120}")
            print(f"{'‚Ññ':<5} {'–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö':<80} {'ID':<35}")
            print(f"{'-' * 120}")
            for idx, record in enumerate(unmatched_avito[:50], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 50
                development = record.get('development', {})
                name = development.get('name') or 'N/A'
                name = name[:78] if name and len(name) > 78 else name
                record_id = str(record['_id'])[:33]
                print(f"{idx:<5} {name:<80} {record_id:<35}")
            if len(unmatched_avito) > 50:
                print(f"... –∏ –µ—â–µ {len(unmatched_avito) - 50} –∑–∞–ø–∏—Å–µ–π")
        else:
            print(f"\n‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ Avito —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã!")

        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π DomClick
        if unmatched_domclick:
            print(f"\n{'=' * 120}")
            print(f"üìã –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ó–ê–ü–ò–°–ò –ò–ó DOMCLICK ({len(unmatched_domclick)} —à—Ç.)")
            print(f"{'=' * 120}")
            print(f"{'‚Ññ':<5} {'–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö':<80} {'ID':<35}")
            print(f"{'-' * 120}")
            for idx, record in enumerate(unmatched_domclick[:50], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 50
                development = record.get('development', {})
                name = development.get('complex_name') or 'N/A'
                name = name[:78] if name and len(name) > 78 else name
                record_id = str(record['_id'])[:33]
                print(f"{idx:<5} {name:<80} {record_id:<35}")
            if len(unmatched_domclick) > 50:
                print(f"... –∏ –µ—â–µ {len(unmatched_domclick) - 50} –∑–∞–ø–∏—Å–µ–π")
        else:
            print(f"\n‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomClick —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã!")

        client.close()

        print(f"\n{'=' * 80}")
        print(f"‚úÖ –û–ë–™–ï–î–ò–ù–ï–ù–ù–ê–Ø –ö–û–õ–õ–ï–ö–¶–ò–Ø –°–û–ó–î–ê–ù–ê: {UNIFIED_COLLECTION_NAME}")
        print(f"{'=' * 80}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


def main():
    print("üîÑ –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
    print("1. –ë–µ—Ä–µ–º –∑–∞–ø–∏—Å—å –∏–∑ DomRF")
    print("2. –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ Avito")
    print("3. –ï—Å–ª–∏ –ù–ï –Ω–∞—à–ª–∏ –≤ Avito ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å")
    print("4. –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –≤ Avito ‚Üí –∏—â–µ–º –≤ DomClick")
    print("5. –ï—Å–ª–∏ –ù–ï –Ω–∞—à–ª–∏ –≤ DomClick ‚Üí —Ç–æ–∂–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å")
    print("6. –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–æ–ª–Ω–æ–π —Ü–µ–ø–æ—á–∫–µ)")
    print()

    create_unified_collection()


if __name__ == "__main__":
    main()
