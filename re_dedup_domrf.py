#!/usr/bin/env python3
"""
–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è DomRF –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
–û–±–Ω–æ–≤–ª—è–µ—Ç normalized_name –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –∏ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã.
"""
import os
import re
from pathlib import Path
from typing import List, Dict, Any

from dotenv import load_dotenv
from pymongo import MongoClient
from pymongo.errors import PyMongoError, DuplicateKeyError


PROJECT_ROOT = Path(__file__).resolve().parent


def load_domrf_env() -> Dict[str, str]:
    env_path = PROJECT_ROOT / 'domrf' / '.env'
    load_dotenv(dotenv_path=env_path)
    return {
        'DB_NAME': os.getenv('DB_NAME'),
        'COLLECTION_NAME': os.getenv('COLLECTION_NAME'),
        'MONGO_URI': os.getenv('MONGO_URI'),
    }


def transliterate_russian_to_latin(text: str) -> str:
    translit_dict = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'Yo',
        '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Sch',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
    }

    result = ''
    for char in text:
        result += translit_dict.get(char, char)
    return result


def normalize_name(name: str) -> str:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –ñ–ö"""
    if not name:
        return ''

    normalized = name.lower()
    normalized = re.sub(r'\([^)]*\)', '', normalized)
    normalized = re.sub(r'[^\w\s]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    common_words = ['–∂–∫', '–∂–∏–ª–æ–π', '–∫–æ–º–ø–ª–µ–∫—Å', '–¥–æ–º–∞', '–∫–≤–∞—Ä—Ç–∏—Ä—ã', '–ø–æ—Å–µ–ª–æ–∫',
                    '–ª–∏—Ç–µ—Ä', '–ª–∏—Ç–µ—Ä–∞', '—Å–µ–∫—Ü–∏–∏', '—ç—Ç–∞–ø', '–æ—á–µ—Ä–µ–¥—å',
                    '–∫–ª—É–±–Ω—ã–π', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '–∫—Ä–∞—Å–æ—á–Ω—ã–π',
                    '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã', '–≤—ã—Å–æ—Ç–Ω—ã—Ö', '—ç–∫–æ–≥–æ—Ä–æ–¥',
                    '–∫–ª—É–±–Ω–∞—è', '—Ä–µ–∑–∏–¥–µ–Ω—Ü–∏—è', '–≥—Ä—É–ø–ø–∞', '–∫–æ–º–ø–∞–Ω–∏–π', '–∫–æ–º–ø–ª–µ–∫—Å–∞']

    significant_words = {'village', '–≤–∏–ª–ª–∏–¥–∂', 'park', '–ø–∞—Ä–∫', 'city', '—Å–∏—Ç–∏',
                         'town', '—Ç–∞—É–Ω', 'garden', '–≥–∞—Ä–¥–µ–Ω', 'house', '—Ö–∞—É—Å',
                         'collection', '–∫–æ–ª–ª–µ–∫—à–Ω', '–∫–≤–∞—Ä—Ç–∞–ª', 'premiere', '–ø—Ä–µ–º—å–µ—Ä',
                         '—É–º–Ω—ã–π', 'smart', '–¥–æ–º', 'the', 'prime'}

    for word in common_words:
        if word not in significant_words:
            normalized = re.sub(r'\b' + word + r'\b', '', normalized)

    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–ª–æ–≤
    words = normalized.split()
    filtered_words = []
    for word in words:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –Ω–æ–º–µ—Ä–∞–º–∏ –ª–∏—Ç–µ—Ä–æ–≤/—Å–µ–∫—Ü–∏–π/—ç—Ç–∞–ø–æ–≤
        if (word.isdigit() or  # –û–¥–∏–Ω–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã
            (len(word) <= 3 and word.isalpha() and word not in significant_words) or  # –ö–æ—Ä–æ—Ç–∫–∏–µ –±—É–∫–≤—ã
            word in ['–ª–∏—Ç–µ—Ä', '–ª–∏—Ç–µ—Ä–∞', '—Å–µ–∫—Ü–∏–∏', '—Å–µ–∫—Ü–∏—è', '—ç—Ç–∞–ø', '–æ—á–µ—Ä–µ–¥—å', '–ø–∞—Ä–∫–∏–Ω–≥']):  # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
            continue
        filtered_words.append(word)

    normalized = ' '.join(filtered_words)
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    transliterated = transliterate_russian_to_latin(normalized)
    if normalized != transliterated:
        return f"{normalized} {transliterated}"
    return normalized


def drop_unique_index(collection):
    """–£–¥–∞–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–∞ normalized_name –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    try:
        collection.drop_index('normalized_name_1')
        print('üóëÔ∏è –£–¥–∞–ª–µ–Ω —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–∞ normalized_name')
    except PyMongoError:
        print('‚ÑπÔ∏è –ò–Ω–¥–µ–∫—Å –Ω–∞ normalized_name –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω')


def update_normalized_names(collection) -> int:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç normalized_name –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    updated = 0
    cursor = collection.find({}, {'objCommercNm': 1, 'normalized_name': 1, '_id': 1})
    
    for doc in cursor:
        obj_name = doc.get('objCommercNm')
        if not obj_name:
            continue
            
        new_normalized = normalize_name(obj_name)
        old_normalized = doc.get('normalized_name')
        
        if old_normalized != new_normalized:
            collection.update_one({'_id': doc['_id']}, {'$set': {'normalized_name': new_normalized}})
            updated += 1
            print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ: '{obj_name}' ‚Üí '{new_normalized}'")
    
    return updated


def remove_duplicates(collection) -> Dict[str, int]:
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ normalized_name"""
    removed = 0
    kept = 0
    
    # –ù–∞—Ö–æ–¥–∏–º –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    pipeline = [
        {'$group': {
            '_id': '$normalized_name', 
            'ids': {'$push': '$_id'}, 
            'count': {'$sum': 1},
            'names': {'$push': '$objCommercNm'}
        }},
        {'$match': {'count': {'$gt': 1}, '_id': {'$ne': None}}}
    ]
    
    for group in collection.aggregate(pipeline):
        ids = group['ids']
        names = group['names']
        normalized = group['_id']
        
        if not ids:
            continue
            
        print(f"\nüìã –ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –¥–ª—è '{normalized}':")
        for i, name in enumerate(names):
            print(f"  {i+1}. {name}")
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç, —É–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
        keep_id = ids[0]
        to_delete = ids[1:]
        
        if to_delete:
            result = collection.delete_many({'_id': {'$in': to_delete}})
            removed += result.deleted_count
            kept += 1
            print(f"  ‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω: {names[0]}")
            print(f"  ‚ùå –£–¥–∞–ª–µ–Ω–æ: {result.deleted_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    return {'removed': removed, 'kept': kept}


def create_unique_index(collection):
    """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–∞ normalized_name"""
    try:
        collection.create_index('normalized_name', unique=True, sparse=True)
        print('‚úÖ –°–æ–∑–¥–∞–Ω —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–∞ –ø–æ–ª–µ normalized_name')
    except DuplicateKeyError:
        print('‚ö†Ô∏è –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å: –Ω–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã')
    except PyMongoError as e:
        print(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {e}')


def main():
    print("üîÑ –ü–û–í–¢–û–†–ù–ê–Ø –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø DOMRF")
    print("="*60)
    
    cfg = load_domrf_env()
    client = MongoClient(cfg['MONGO_URI'])
    db = client[cfg['DB_NAME']]
    collection = db[cfg['COLLECTION_NAME']]

    print(f"üìä –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –±–∞–∑–µ: {cfg['DB_NAME']}")
    print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è: {cfg['COLLECTION_NAME']}")
    print(f"üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {collection.count_documents({})}")
    
    print('\nüóëÔ∏è –£–¥–∞–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å...')
    drop_unique_index(collection)
    
    print('\nüì• –û–±–Ω–æ–≤–ª—è–µ–º normalized_name –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')
    updated = update_normalized_names(collection)
    print(f'‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {updated}')

    print('\nüßπ –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ normalized_name...')
    stats = remove_duplicates(collection)
    print(f"\n‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {stats['kept']}")
    print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['removed']}")

    print('\nüîí –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å...')
    create_unique_index(collection)
    
    print(f'\nüìä –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {collection.count_documents({})}')

    client.close()
    print('\nüéâ –ì–æ—Ç–æ–≤–æ!')


if __name__ == '__main__':
    main()
