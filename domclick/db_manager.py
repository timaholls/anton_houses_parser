#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MongoDB
–°–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from pymongo import MongoClient
from dotenv import load_dotenv
from urllib.parse import urlparse

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
PROJECT_ROOT = Path(__file__).resolve().parent

load_dotenv(dotenv_path=PROJECT_ROOT / ".env")
# MongoDB –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = os.getenv("DB_NAME")
COLLECTION_NAME = os.getenv("COLLECTION_NAME")


def get_mongo_client():
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB"""
    try:
        client = MongoClient(MONGO_URI)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        client.admin.command('ping')
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å–ø–µ—à–Ω–æ: {MONGO_URI}")
        return client
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB: {e}")
        return None


def normalize_complex_url(url: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç URL –∫–æ–º–ø–ª–µ–∫—Å–∞, –ø—Ä–∏–≤–æ–¥—è –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
    –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç ufa.domclick.ru –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è.
    """
    if not url:
        return url
    
    try:
        parsed = urlparse(url)
        path_parts = parsed.path.split('/')
        if 'complexes' in path_parts:
            complex_index = path_parts.index('complexes')
            if complex_index + 1 < len(path_parts):
                slug = path_parts[complex_index + 1]
                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º ufa.domclick.ru
                return f"https://ufa.domclick.ru/complexes/{slug}"
    except Exception:
        pass
    
    return url


def find_existing_record(collection, url: str):
    """
    –ò—â–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å –ø–æ URL, —É—á–∏—Ç—ã–≤–∞—è —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ–º–µ–Ω–æ–≤.
    –ò—â–µ—Ç –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É URL –∏ –ø–æ slug –∫–æ–º–ø–ª–µ–∫—Å–∞.
    """
    if not url:
        return None
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
    normalized_url = normalize_complex_url(url)
    
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ URL
    existing = collection.find_one({'url': normalized_url})
    if existing:
        return existing
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É URL
    if url != normalized_url:
        existing = collection.find_one({'url': url})
        if existing:
            return existing
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ slug –∫–æ–º–ø–ª–µ–∫—Å–∞
    try:
        parsed = urlparse(normalized_url)
        path_parts = parsed.path.split('/')
        if 'complexes' in path_parts:
            complex_index = path_parts.index('complexes')
            if complex_index + 1 < len(path_parts):
                slug = path_parts[complex_index + 1]
                # –ò—â–µ–º –∑–∞–ø–∏—Å–∏, –≥–¥–µ URL —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–æ—Ç slug
                existing = collection.find_one({
                    'url': {'$regex': f'/complexes/{slug}'}
                })
                if existing:
                    return existing
    except Exception:
        pass
    
    return None


def compare_and_merge_data(existing_data, new_data):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ, –æ–±–Ω–æ–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è —á–∞—Å—Ç–∏"""
    if not existing_data:
        return new_data, []
    
    merged = existing_data.copy()
    changes = []
    
    # –û–±–Ω–æ–≤–ª—è–µ–º development —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if 'development' in new_data and new_data['development']:
        for key, value in new_data['development'].items():
            if value:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
                if key not in merged.get('development', {}) or merged['development'][key] != value:
                    if 'development' not in merged:
                        merged['development'] = {}
                    merged['development'][key] = value
                    changes.append(f"development.{key}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º apartment_types - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ —Ç–∏–ø—É –∫–≤–∞—Ä—Ç–∏—Ä—ã
    if 'apartment_types' in new_data and new_data['apartment_types']:
        if 'apartment_types' not in merged:
            merged['apartment_types'] = {}
        
        for apt_type, apt_data in new_data['apartment_types'].items():
            if apt_data and 'apartments' in apt_data:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–≤–∞—Ä—Ç–∏—Ä
                old_apartments = merged['apartment_types'].get(apt_type, {}).get('apartments', [])
                new_apartments = apt_data['apartments']
                
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –Ω–æ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ (–æ—Å–æ–±–µ–Ω–Ω–æ –ø—É—Ç–∏ –∫ —Ñ–æ—Ç–æ)
                apartments_changed = False
                if len(old_apartments) != len(new_apartments):
                    apartments_changed = True
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö –∫–≤–∞—Ä—Ç–∏—Ä
                    for old_apt, new_apt in zip(old_apartments, new_apartments):
                        old_photos = old_apt.get('photos', [])
                        new_photos = new_apt.get('photos', [])
                        if old_photos != new_photos:
                            apartments_changed = True
                            break
                
                if apt_type not in merged['apartment_types'] or apartments_changed:
                    merged['apartment_types'][apt_type] = apt_data
                    old_count = len(old_apartments)
                    new_count = len(new_apartments)
                    changes.append(f"apartment_types.{apt_type} ({old_count} ‚Üí {new_count} –∫–≤–∞—Ä—Ç–∏—Ä)")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º total_apartments
    if 'apartment_types' in merged:
        merged['total_apartments'] = sum(
            len(apt_data.get('apartments', [])) 
            for apt_data in merged['apartment_types'].values()
        )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º scraped_at
    merged['scraped_at'] = new_data.get('scraped_at', datetime.now().isoformat())
    
    return merged, changes


def save_to_mongodb(data):
    """–£–º–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –ø–æ–∏—Å–∫–æ–º –ø–æ URL –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
    try:
        client = get_mongo_client()
        if not client:
            return False
            
        db = client[DB_NAME]
        collection = db[COLLECTION_NAME]
        
        for item in data:
            url = item.get('url')
            if not url:
                print("‚ö†Ô∏è URL –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            normalized_url = normalize_complex_url(url)
            item['url'] = normalized_url  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π URL
            
            # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å –ø–æ URL (—Å —É—á–µ—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–æ–º–µ–Ω–æ–≤)
            existing = find_existing_record(collection, normalized_url)
            
            if existing:
                existing_url = existing.get('url', '')
                print(f"üìù –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è: {existing_url} (–∏—Å–∫–∞–ª–∏: {normalized_url})")
                
                # –ï—Å–ª–∏ URL –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è, –æ–±–Ω–æ–≤–ª—è–µ–º –µ–≥–æ –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π
                if existing_url != normalized_url:
                    print(f"  –û–±–Ω–æ–≤–ª—è—é URL —Å {existing_url} –Ω–∞ {normalized_url}")
                
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                merged_data, changes = compare_and_merge_data(existing, item)
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ URL –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω
                merged_data['url'] = normalized_url
                
                if changes:
                    print(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è:")
                    for change in changes:
                        print(f"   - {change}")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –ø–æ _id —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
                    collection.update_one(
                        {'_id': existing['_id']},
                        {'$set': merged_data}
                    )
                    print(f"‚úÖ –ó–∞–ø–∏—Å—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
                else:
                    # –î–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π, –æ–±–Ω–æ–≤–ª—è–µ–º URL –µ—Å–ª–∏ –æ–Ω –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è
                    if existing_url != normalized_url:
                        collection.update_one(
                            {'_id': existing['_id']},
                            {'$set': {'url': normalized_url}}
                        )
                        print(f"‚úÖ URL –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π")
                    else:
                        print(f"‚ÑπÔ∏è –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∑–∞–ø–∏—Å—å –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
            else:
                print(f"‚ûï –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è: {normalized_url}")
                # –£–¥–∞–ª—è–µ–º _id –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if '_id' in item:
                    del item['_id']
                collection.insert_one(item)
                print(f"‚úÖ –ù–æ–≤–∞—è –∑–∞–ø–∏—Å—å —Å–æ–∑–¥–∞–Ω–∞")
        
        client.close()
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ MongoDB: {e}")
        return False

