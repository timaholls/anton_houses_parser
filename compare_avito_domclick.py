#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∫–æ–ª–ª–µ–∫—Ü–∏—è–º–∏ Avito –∏ DomClick –±–µ–∑ DomRF.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª—å –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
"""
import json
import os
import re
from pathlib import Path
from pymongo import MongoClient
from dotenv import load_dotenv
from typing import Dict, List, Any, Optional
from rapidfuzz import fuzz

# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
PROJECT_ROOT = Path(__file__).resolve().parent


def load_env_from_parser(parser_name):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
    env_path = PROJECT_ROOT / parser_name / ".env"
    if env_path.exists():
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        original_env = dict(os.environ)

        # –û—á–∏—â–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for key in ['DB_NAME', 'COLLECTION_NAME', 'MONGO_URI']:
            if key in os.environ:
                del os.environ[key]

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ .env —Ñ–∞–π–ª–∞
        load_dotenv(dotenv_path=env_path, override=True)

        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        config = {
            "DB_NAME": os.getenv("DB_NAME"),
            "COLLECTION_NAME": os.getenv("COLLECTION_NAME"),
            "MONGO_URI": os.getenv("MONGO_URI")
        }

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        os.environ.clear()
        os.environ.update(original_env)

        return config
    return None


def transliterate_russian_to_latin(text: str) -> str:
    """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É"""
    translit_dict = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'Yo',
        '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Sch',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
    }

    result = ""
    for char in text:
        result += translit_dict.get(char, char)
    return result


def normalize_name(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ñ–ö –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
    if not name:
        return ""

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    normalized = name.lower()

    # –£–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—á–∞—Å—Ç–æ —Ç–∞–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
    normalized = re.sub(r'\([^)]*\)', '', normalized)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–±–µ–ª—ã
    normalized = re.sub(r'[^\w\s]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–Ω–æ –ù–ï —É–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ —Ç–∏–ø–∞ "village", "park")
    common_words = ['–∂–∫', '–∂–∏–ª–æ–π', '–∫–æ–º–ø–ª–µ–∫—Å', '–¥–æ–º–∞', '–∫–≤–∞—Ä—Ç–∏—Ä—ã', '–ø–æ—Å–µ–ª–æ–∫',
                    '–ª–∏—Ç–µ—Ä', '–ª–∏—Ç–µ—Ä–∞', '—Å–µ–∫—Ü–∏–∏', '—ç—Ç–∞–ø', '–æ—á–µ—Ä–µ–¥—å',
                    '–∫–ª—É–±–Ω—ã–π', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '—Å–µ–º–µ–π–Ω—ã–π', '–∫—Ä–∞—Å–æ—á–Ω—ã–π',
                    '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã', '–≤—ã—Å–æ—Ç–Ω—ã—Ö', '—ç–∫–æ–≥–æ—Ä–æ–¥',
                    '–∫–ª—É–±–Ω–∞—è', '—Ä–µ–∑–∏–¥–µ–Ω—Ü–∏—è', '–≥—Ä—É–ø–ø–∞', '–∫–æ–º–ø–∞–Ω–∏–π', '–∫–æ–º–ø–ª–µ–∫—Å–∞']

    # –ó–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –¥–æ–ª–∂–Ω—ã —É–¥–∞–ª—è—Ç—å—Å—è
    significant_words = {'village', '–≤–∏–ª–ª–∏–¥–∂', 'park', '–ø–∞—Ä–∫', 'city', '—Å–∏—Ç–∏',
                         'town', '—Ç–∞—É–Ω', 'garden', '–≥–∞—Ä–¥–µ–Ω', 'house', '—Ö–∞—É—Å',
                         'collection', '–∫–æ–ª–ª–µ–∫—à–Ω', '–∫–≤–∞—Ä—Ç–∞–ª', 'premiere', '–ø—Ä–µ–º—å–µ—Ä',
                         '—É–º–Ω—ã–π', 'smart', '–¥–æ–º', 'the', 'prime'}

    for word in common_words:
        # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ–µ (–Ω–µ —á–∞—Å—Ç—å –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞) –∏ –Ω–µ –∑–Ω–∞—á–∏–º–æ–µ
        if word not in significant_words:
            normalized = re.sub(r'\b' + word + r'\b', '', normalized)

    # –£–±–∏—Ä–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ —Å—Ç–æ—è—â–∏–µ —Ü–∏—Ñ—Ä—ã –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –±—É–∫–≤—ã (–Ω–æ–º–µ—Ä–∞ –ª–∏—Ç–µ—Ä–æ–≤, —ç—Ç–∞–ø–æ–≤, —Å–µ–∫—Ü–∏–π)
    # –ù–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ñ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏—è (8 –º–∞—Ä—Ç–∞, 535)
    words = normalized.split()
    filtered_words = []
    for i, word in enumerate(words):
        # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–∏–Ω–æ—á–Ω–∞—è —Ü–∏—Ñ—Ä–∞ –∏–ª–∏ 1-2 –±—É–∫–≤—ã –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è (–Ω–æ –Ω–µ –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞)
        if len(filtered_words) > 0 and (
                word.isdigit() or (len(word) <= 2 and word.isalpha() and word not in significant_words)):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ –ª–∏—Ç–µ—Ä–æ–≤/—Å–µ–∫—Ü–∏–π –ø–æ—Å–ª–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            continue
        filtered_words.append(word)

    normalized = ' '.join(filtered_words)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤
    normalized = re.sub(r'\s+', ' ', normalized).strip()

    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    transliterated = transliterate_russian_to_latin(normalized)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    if normalized != transliterated:
        return f"{normalized} {transliterated}"
    else:
        return normalized


def normalize_name_simple(name: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è rapidfuzz"""
    if not name:
        return ""
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    name = name.lower().strip()
    
    # –£–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏, –ø–æ—è—Å–Ω–µ–Ω–∏—è)
    name = re.sub(r'\([^)]*\)', '', name)
    
    # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã (–≤–∫–ª—é—á–∞—è —Ç–æ—á–∫–∏, —Ç–∏—Ä–µ, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
    name = re.sub(r'[¬´¬ª""\[\].‚Äî‚Äì\-_&]', ' ', name)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
    prefixes = ['–∂–∫', '—Ç–æ–∫', '–∫–æ–º–ø–ª–µ–∫—Å –∂–∏–ª—ã—Ö –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', '–∫–æ–º–ø–ª–µ–∫—Å –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤', 
                '–∫–æ–º–ø–ª–µ–∫—Å –≤—ã—Å–æ—Ç–Ω—ã—Ö –¥–æ–º–æ–≤', '–∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å', '–∫–ª—É–±–Ω—ã–π –¥–æ–º', 
                '–∫–ª—É–±–Ω–∞—è —Ä–µ–∑–∏–¥–µ–Ω—Ü–∏—è', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '—Å–µ–º–µ–π–Ω—ã–π –∫–≤–∞—Ä—Ç–∞–ª', 
                '–∑–Ω–∞–∫–æ–≤—ã–π –∫–≤–∞—Ä—Ç–∞–ª', '–∫—Ä–∞—Å–æ—á–Ω—ã–π –∫–≤–∞—Ä—Ç–∞–ª', '–∫–≤–∞—Ä—Ç–∞–ª']
    
    for prefix in prefixes:
        pattern = r'\b' + re.escape(prefix) + r'\b\s*'
        name = re.sub(pattern, '', name, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    name = re.sub(r'\s+', ' ', name).strip()
    
    return name


def calculate_similarity_rapidfuzz(name1: str, name2: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –ñ–ö –∏—Å–ø–æ–ª—å–∑—É—è rapidfuzz —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
    if not name1 or not name2:
        return 0.0
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
    norm1 = normalize_name_simple(name1)
    norm2 = normalize_name_simple(name2)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä—è–º–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–æ–±–∞ –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ –∏–ª–∏ –æ–±–∞ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_direct = fuzz.token_sort_ratio(norm1, norm2, processor=str.lower)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –æ–±–∞ –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    trans1 = transliterate_russian_to_latin(norm1)
    trans2 = transliterate_russian_to_latin(norm2)
    ratio_transliterated = fuzz.token_sort_ratio(trans1, trans2, processor=str.lower)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 3: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º norm1 —Å trans2 (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ –æ–¥–∏–Ω —É–∂–µ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_cross1 = fuzz.token_sort_ratio(norm1, trans2, processor=str.lower)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 4: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º trans1 —Å norm2 (–¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ –≤—Ç–æ—Ä–æ–π —É–∂–µ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ)
    ratio_cross2 = fuzz.token_sort_ratio(trans1, norm2, processor=str.lower)
    
    # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    max_ratio = max(ratio_direct, ratio_transliterated, ratio_cross1, ratio_cross2)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ 0-1 –¥–∏–∞–ø–∞–∑–æ–Ω
    return max_ratio / 100.0


def calculate_similarity(name1: str, name2: str) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –ñ–ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏.
    –ö–ª—é—á–µ–≤–∞—è –ª–æ–≥–∏–∫–∞:
    - –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ - –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
    - –ï—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è (village, park –∏ —Ç.–¥.) - –Ω–∏–∑–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
    """
    if not name1 or not name2:
        return 0.0

    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if name1 == name2:
        return 1.0

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words1 = set(name1.split())
    words2 = set(name2.split())

    if not words1 or not words2:
        return 0.0

    # –°–ø–∏—Å–æ–∫ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å
    significant_words = {'village', '–≤–∏–ª–ª–∏–¥–∂', 'park', '–ø–∞—Ä–∫', 'city', '—Å–∏—Ç–∏',
                         'town', '—Ç–∞—É–Ω', 'garden', '–≥–∞—Ä–¥–µ–Ω', 'house', '—Ö–∞—É—Å',
                         'collection', '–∫–æ–ª–ª–µ–∫—à–Ω', '–∫–≤–∞—Ä—Ç–∞–ª', 'premiere', '–ø—Ä–µ–º—å–µ—Ä',
                         '—É–º–Ω—ã–π', 'smart', '–¥–æ–º', 'the', 'prime'}

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤
    significant_in_1 = words1.intersection(significant_words)
    significant_in_2 = words2.intersection(significant_words)

    # –ï—Å–ª–∏ –≤ –æ–¥–Ω–æ–º –µ—Å—Ç—å –∑–Ω–∞—á–∏–º–æ–µ —Å–ª–æ–≤–æ, –∞ –≤ –¥—Ä—É–≥–æ–º –Ω–µ—Ç - —ç—Ç–æ —Ä–∞–∑–Ω—ã–µ –ñ–ö
    if significant_in_1 != significant_in_2:
        # –î–∞–∂–µ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø–æ—Ö–æ–∂–∞, —ç—Ç–æ —Ä–∞–∑–Ω—ã–µ –∫–æ–º–ø–ª–µ–∫—Å—ã
        return 0.6  # –ù–µ –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç –ø–æ—Ä–æ–≥–∞ 0.8

    # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ –∏ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã)
    stop_words = {'–Ω–æ–≤—ã–π', '—Å—Ç–∞—Ä—ã–π', '–±–æ–ª—å—à–æ–π', '–º–∞–ª–µ–Ω—å–∫–∏–π'}

    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
    filtered_words1 = {word for word in words1 if word not in stop_words}
    filtered_words2 = {word for word in words2 if word not in stop_words}

    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–æ–≤
    if not filtered_words1 or not filtered_words2:
        return 0.0

    # –û–¥–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä—É–≥–æ–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é
    if filtered_words1 == filtered_words2:
        return 1.0

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    # –ò—â–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
    all_words1 = filtered_words1.copy()
    all_words2 = filtered_words2.copy()

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
    for word in list(filtered_words1):
        if any(ord(c) > 127 for c in word):  # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
            transliterated = transliterate_russian_to_latin(word)
            if transliterated != word:
                all_words1.add(transliterated)

    for word in list(filtered_words2):
        if any(ord(c) > 127 for c in word):  # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
            transliterated = transliterate_russian_to_latin(word)
            if transliterated != word:
                all_words2.add(transliterated)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    common_words = all_words1.intersection(all_words2)

    if common_words:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–≤–∫–ª—é—á–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏), –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        similarity1 = len(common_words) / len(filtered_words1)
        similarity2 = len(common_words) / len(filtered_words2)

        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ –º—è–≥–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        avg_similarity = (similarity1 + similarity2) / 2

        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
        if avg_similarity >= 0.7:
            return min(0.95, avg_similarity + 0.1)  # –ë–æ–Ω—É—Å –∑–∞ —Ö–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        elif avg_similarity >= 0.5:
            return avg_similarity * 0.95
        else:
            return avg_similarity * 0.8

    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º—ã—Ö –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    if filtered_words1.issubset(all_words2):
        extra_words = all_words2 - filtered_words1
        if len(extra_words) <= 4:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
            return 0.9
        return 0.8

    if filtered_words2.issubset(all_words1):
        extra_words = all_words1 - filtered_words2
        if len(extra_words) <= 4:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–π
            return 0.9
        return 0.8

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    for word1 in filtered_words1:
        for word2 in filtered_words2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if word1 == word2:
                return 0.85  # –•–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
            if len(word1) > 3 and len(word2) > 3:  # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤
                translit1 = transliterate_russian_to_latin(word1)
                translit2 = transliterate_russian_to_latin(word2)

                if translit1 == word2 or word1 == translit2 or translit1 == translit2:
                    return 0.9  # –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏

    return 0.0


def find_matching_domclick_record(avito_name: str, domclick_collection, used_domclick_ids: set) -> Optional[Dict]:
    """–ò—â–µ—Ç –∑–∞–ø–∏—Å—å –≤ DomClick –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ñ–ö –∏–∑ Avito"""
    if not avito_name:
        return None

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ Avito
    normalized_avito = normalize_name(avito_name)
    print(f"üîç Avito: '{avito_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_avito}'")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ DomClick, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
    domclick_records = list(domclick_collection.find({'_id': {'$nin': list(used_domclick_ids)}}))

    best_match = None
    best_score = 0
    comparison_count = 0

    for record in domclick_records:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ development.complex_name
        development = record.get('development', {})
        domclick_name = development.get('complex_name', '')

        if not domclick_name:
            continue

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ DomClick
        normalized_domclick = normalize_name(domclick_name)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É—è rapidfuzz
        similarity_score = calculate_similarity_rapidfuzz(avito_name, domclick_name)
        comparison_count += 1

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å > 0.3 (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
        if similarity_score > 0.3:
            print(
                f"  üìã DomClick: '{domclick_name}' ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{normalized_domclick}' | –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")

        if similarity_score > best_score and similarity_score > 0.60:  # –°–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            print(f"    ‚úÖ –ù–û–í–û–ï –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï! –°—Ö–æ–∂–µ—Å—Ç—å: {similarity_score:.2f}")
            best_score = similarity_score
            best_match = record
        elif similarity_score > 0.5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±–ª–∏–∑–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            print(f"    ‚ö†Ô∏è  –ë–ª–∏–∑–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–Ω—É–∂–Ω–æ >0.60)")

    print(f"üìä –°—Ä–∞–≤–Ω–µ–Ω–æ —Å {comparison_count} –∑–∞–ø–∏—Å—è–º–∏ –∏–∑ DomClick")
    if best_match:
        development = best_match.get('development', {})
        domclick_name = development.get('complex_name', '')
        print(f"üèÜ –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï: '{domclick_name}' (—Å—Ö–æ–∂–µ—Å—Ç—å: {best_score:.2f})")
    else:
        print(f"‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: 0.60)")

    print()
    return best_match


def compare_avito_domclick():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –º–µ–∂–¥—É Avito –∏ DomClick"""
    print("üîç –°–†–ê–í–ù–ï–ù–ò–ï AVITO ‚Üî DOMCLICK")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    avito_config = load_env_from_parser('avito')
    domclick_config = load_env_from_parser('domclick')

    if not all([avito_config, domclick_config]):
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MongoDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Avito –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é)
        client = MongoClient(avito_config['MONGO_URI'])
        db = client[avito_config['DB_NAME']]

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        avito_collection = db[avito_config['COLLECTION_NAME']]
        domclick_collection = db[domclick_config['COLLECTION_NAME']]

        print(f"üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {avito_config['DB_NAME']}")
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è Avito: {avito_config['COLLECTION_NAME']}")
        print(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è DomClick: {domclick_config['COLLECTION_NAME']}")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ Avito
        print(f"\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–ø–∏—Å–∏ –∏–∑ Avito...")
        avito_records = list(avito_collection.find())
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(avito_records)} –∑–∞–ø–∏—Å–µ–π –∏–∑ Avito")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_processed = 0
        total_matched = 0
        total_skipped = 0
        matches_details = []
        unmatched_avito = []
        unmatched_domclick = []
        used_domclick_ids = set()

        print(f"\nüîÑ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–ü–ò–°–ï–ô:")
        print("=" * 80)

        for i, avito_record in enumerate(avito_records):
            if i % 5 == 0:
                print(f"\nüìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å—å {i + 1}/{len(avito_records)}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ development.name
            development = avito_record.get('development', {})
            avito_name = development.get('name', '')

            if not avito_name:
                total_skipped += 1
                continue

            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ DomClick (–∏—Å–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ)
            domclick_match = find_matching_domclick_record(avito_name, domclick_collection, used_domclick_ids)

            total_processed += 1

            if domclick_match:
                total_matched += 1
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö
                used_domclick_ids.add(domclick_match['_id'])

                domclick_development = domclick_match.get('development', {})
                domclick_name = domclick_development.get('complex_name', '')

                match_info = {
                    'avito_name': avito_name,
                    'domclick_name': domclick_name,
                    'avito_id': str(avito_record.get('_id')),
                    'domclick_id': str(domclick_match.get('_id'))
                }
                matches_details.append(match_info)
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö Avito
                unmatched_avito.append({
                    'name': avito_name,
                    'id': str(avito_record.get('_id')),
                    'reason': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ DomClick'
                })

        # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ DomClick
        print(f"\nüìã –°–æ–±–∏—Ä–∞–µ–º –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ DomClick...")
        domclick_records = list(domclick_collection.find())
        for record in domclick_records:
            if record['_id'] not in used_domclick_ids:
                development = record.get('development', {})
                domclick_name = development.get('complex_name', '')
                if domclick_name:
                    unmatched_domclick.append({
                        'name': domclick_name,
                        'id': str(record.get('_id')),
                        'reason': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ Avito'
                    })

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\n{'=' * 80}")
        print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print("=" * 80)
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ Avito: {len(avito_records)}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ DomClick: {len(domclick_records)}")
        print(f"  ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π Avito: {total_processed}")
        print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è): {total_skipped}")
        print(f"  ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matched}")
        print(
            f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {(total_matched / total_processed * 100):.1f}%" if total_processed > 0 else "  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: 0.0%")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        if matches_details:
            print(f"\nüèÜ –î–ï–¢–ê–õ–ò –°–û–í–ü–ê–î–ï–ù–ò–ô:")
            print("-" * 80)
            for i, match in enumerate(matches_details[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"{i:2d}. Avito: '{match['avito_name']}'")
                print(f"    DomClick: '{match['domclick_name']}'")
                print(f"    IDs: Avito({match['avito_id'][:12]}...), DomClick({match['domclick_id'][:12]}...)")
                print()

            if len(matches_details) > 10:
                print(f"    ... –∏ –µ—â—ë {len(matches_details) - 10} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")

        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        if unmatched_avito:
            print(f"\nüìã –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ó–ê–ü–ò–°–ò –ò–ó AVITO ({len(unmatched_avito)} —à—Ç.)")
            print("=" * 80)
            print(f"{'‚Ññ':<4} {'–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö':<60} {'ID':<20} {'–ü—Ä–∏—á–∏–Ω–∞'}")
            print("-" * 80)
            for i, record in enumerate(unmatched_avito, 1):
                name = record['name']
                name = name[:58] if name and len(name) > 58 else name
                print(f"{i:<4} {name:<60} {record['id'][:18]:<20} {record['reason']}")

        if unmatched_domclick:
            print(f"\nüìã –ù–ï–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ó–ê–ü–ò–°–ò –ò–ó DOMCLICK ({len(unmatched_domclick)} —à—Ç.)")
            print("=" * 80)
            print(f"{'‚Ññ':<4} {'–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö':<60} {'ID':<20} {'–ü—Ä–∏—á–∏–Ω–∞'}")
            print("-" * 80)
            for i, record in enumerate(unmatched_domclick, 1):
                name = record['name']
                name = name[:58] if name and len(name) > 58 else name
                print(f"{i:<4} {name:<60} {record['id'][:18]:<20} {record['reason']}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
        results_file = PROJECT_ROOT / "avito_domclick_comparison.json"
        results = {
            'statistics': {
                'total_avito_records': len(avito_records),
                'processed_records': total_processed,
                'skipped_records': total_skipped,
                'matched_records': total_matched,
                'match_percentage': (total_matched / total_processed * 100) if total_processed > 0 else 0
            },
            'matches': matches_details
        }

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")

        client.close()

        print(f"\n{'=' * 80}")
        print("‚úÖ –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"{'=' * 80}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


def main():
    compare_avito_domclick()


if __name__ == "__main__":
    main()
